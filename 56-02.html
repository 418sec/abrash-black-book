<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta name="vsisbn" content="1576101746" />
  <meta name="vstitle" content="Michael Abrash's Graphics Programming Black Book, Special Edition" />
  <meta name="vsauthor" content="Michael Abrash" />
  <meta name="vspublisher" content="The Coriolis Group" />
  <meta name="vspubdate" content="07/01/97" />
  <meta name="vscategory" content="Web and Software Development: Game Development,Web and Software Development: Graphics and Multimedia Development" />

  <title>Michael Abrash's Graphics Programming Black Book Special Edition: Pooh and the Space Station</title>
  <meta name="chapter" content="56" />
  <meta name="pages" content="1050-1053" />
</head>

<body>
  <center>
    <table border="1">
      <tr>
        <td>
          <a href="56-01.html">Previous</a>
        </td>

        <td>
          <a href="index.html">Table of Contents</a>
        </td>

        <td>
          <a href="56-03.html">Next</a>
        </td>
      </tr>
    </table>
  </center>

  <p>Ah, but what is an &ldquo;equivalent amount&rdquo;? Think of it this way. If a destination edge is 100 scan lines high, it will be stepped 100 times. Then, we&rsquo;ll divide the <b>SourceXWidth</b> and <b>SourceYHeight</b> lengths of the source edge by 100, and add those amounts to the source edge&rsquo;s coordinates each time the destination is stepped one scan line. Put another way, we have, as usual, arranged things so that in the destination polygon we step <b>DestYHeight</b> times, where <b>DestYHeight</b> is the height of the destination edge. The this approach arranges to step the source image edge <b>DestYHeight</b> times also, to match what the destination is doing.</p>

  <p><a id="Fig3"><img src="images/56-03.jpg" /><br />
  <b>Figure 56.3</b></a>&nbsp;&nbsp;<i>Mapping a texture onto a 2-D rotated polygon.</i></p>

  <p>Now we&rsquo;re able to track the coordinates of the polygon edges through the source image in tandem with the destination edges. Stepping across each destination scan line uses precisely the same technique, as shown in Figure 56.4. In the destination, we step <b>DestXWidth</b> times across each scan line of the polygon, once for each pixel on the scan line. (<b>DestXWidth</b> is the horizontal distance between the two edges being scanned on any given scan line.) To match this, we divide <b>SourceXWidth</b> and <b>SourceYHeight</b> (the lengths of the scan line in the source image, as determined by the source edge points we&rsquo;ve been tracking, as just described) by the width of the destination scan line, <b>DestXWidth</b>, to produce <b>SourceXStep</b> and <b>SourceYStep</b>. Then, we just step <b>DestXWidth</b> times, adding <b>SourceXStep</b> and <b>SourceYStep</b> to <b>SourceX</b> and <b>SourceY</b> each time, and choose the nearest image pixel to (<b>SourceX</b>,<b>SourceY</b>) to copy to (<b>DestX</b>, <b>DestY</b>). (Note that the names used above, such as <b>SourceXWidth</b>, are used for descriptive purposes, and don&rsquo;t necessarily correspond to the actual variable names used in Listing 56.2.)</p>

  <p>That&rsquo;s a workable approach for 2-D rotated polygons&mdash;but what about 3-D rotated polygons, where the visible dimensions of the polygon can vary with 3-D rotation and perspective projection? First, I&rsquo;d like to make it clear that texture mapping takes place from the source image to the destination polygon after the destination polygon is projected to the screen. That is, the image will be mapped after the destination polygon is in its final, drawable form. Given that, it should be apparent that the above approach automatically compensates for all changes in the dimensions of a polygon. You see, this approach divides source edges and scan lines into however many steps the destination polygon requires. If the destination polygon is much narrower than the source polygon, as a result of 3-D rotation and perspective projection, we just end up taking bigger steps through the source image and skipping a lot of source image pixels, as shown in Figure 56.5. The upshot is that the above approach handles all transformations and projections effortlessly. It could also be used to scale source images up to fit in larger polygons; all that&rsquo;s needed is a list of where the polygon&rsquo;s vertices map into the source image, and everything else happens automatically. In fact, mapping from any polygonal area of a bitmap to any destination polygon will work, given only that the two polygons have the same number of vertices.</p>

  <p><a id="Fig4"><img src="images/56-04.jpg" /><br />
  <b>Figure 56.4</b></a>&nbsp;&nbsp;<i>Mapping a horizontal destination scan line back to the source image.</i></p>

  <p><a id="Fig5"><img src="images/56-05.jpg" /><br />
  <b>Figure 56.5</b></a>&nbsp;&nbsp;<i>Mapping a texture onto a narrower polygon.</i></p>

  <h4 id="Heading5">Notes on DDA Texture Mapping<br />
  <br /></h4>

  <p>That&rsquo;s all there is to quick-and-dirty texture mapping. This technique basically uses a two-stage digital differential analyzer (DDA) approach to step through the appropriate part of the source image in tandem with the normal scan-line stepping through the destination polygon, so I&rsquo;ll call it &ldquo;DDA texture mapping.&rdquo; It&rsquo;s worth noting that there is no need for any trigonometric functions at all, and only two divides are required per scan line.</p>

  <p>This isn&rsquo;t a perfect approach, of course. For one thing, it isn&rsquo;t anywhere near as fast as drawing solid polygons; the speed is more comparable to drawing each polygon as a series of lines. Also, the DDA approach results in far from perfect image quality, since source pixels may be skipped or selected twice. I trust, however, that you can see how easy it would be to improve image quality by antialiasing with the DDA approach. For example, we could simply average the four surrounding pixels as we did for simple, unweighted antialiasing in Chapters F, G,Chapter K on the companion CD-ROM. Or, we could take a Wu antialiasing approach (see Chapter 57) and average the two bracketing pixels along each axis according to proximity. If we had cycles to waste (which, given that this is real-time animation on a PC, we don&rsquo;t), we could improve image quality by putting the source pixels through a low-pass filter sized in X and Y according to the ratio of the source and destination dimensions (that is, how much the destination is scaled up or down from the source).</p>

  <p>Even more important is that the sort of texture mapping I&rsquo;ll do in X-Sharp doesn&rsquo;t correct for perspective. That doesn&rsquo;t much matter for small polygons or polygons that are nearly parallel to the screen in 3-space, but it can produce very noticeable bowing of textures on large polygons at an angle to the screen. Perspective texture mapping is a complex subject that&rsquo;s outside the scope of this book, but you should be aware of its existence, because perspective texture mapping is a key element of many games these days.</p>

  <p>Finally, I&rsquo;d like to point out that this sort of DDA texture mapping is display-hardware dependent, because the bitmap for each image must be compatible with the number of bits per pixel in the destination. That&rsquo;s actually a fairly serious issue. One of the nice things about X-Sharp&rsquo;s polygon orientation is that, until now, the only display dependent part of X-Sharp has been the transformation from RGB color space to the adapter&rsquo;s color space. Compensation for aspect ratio, resolution, and the like all happens automatically in the course of projection. Still, we need the ability to display detailed surfaces, and it&rsquo;s hard to conceive of a fast way to do so that&rsquo;s totally hardware independent. (If you know of one, let me know care of the publisher.)</p>

  <p>For now, all we need is fast texture mapping of adequate quality, which the straightforward, non-antialiased DDA approach supplies. I&rsquo;m sure there are many other fast approaches, and, as I&rsquo;ve said, there are more accurate approaches, but DDA texture mapping works well, given the constraints of the PC&rsquo;s horsepower. Next, we&rsquo;ll look at code that performs DDA texture mapping. First, though, I&rsquo;d like to take a moment to thank Jim Kent, author of Autodesk Animator and a frequent correspondent, for getting me started with the DDA approach.</p>

  <center>
    <table border="1">
      <tr>
        <td>
          <a href="56-01.html">Previous</a>
        </td>

        <td>
          <a href="index.html">Table of Contents</a>
        </td>

        <td>
          <a href="56-03.html">Next</a>
        </td>
      </tr>
    </table>
  </center>
  <hr width="90%" size="1" noshade="noshade" />

  <div align="center">
    Graphics Programming Black Book &copy; 2001 Michael Abrash
  </div>
</body>
</html>
