<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta name="vsisbn" content="1576101746" />
  <meta name="vstitle" content="Michael Abrash's Graphics Programming Black Book, Special Edition" />
  <meta name="vsauthor" content="Michael Abrash" />
  <meta name="vspublisher" content="The Coriolis Group" />
  <meta name="vspubdate" content="07/01/97" />
  <meta name="vscategory" content="Web and Software Development: Game Development,Web and Software Development: Graphics and Multimedia Development" />

  <title>Michael Abrash's Graphics Programming Black Book Special Edition: Pushing the 486</title><!-- HEADER -->
  <!-- Empty Reference Subhead -->
  <!--ISBN=1576101746//-->
  <!--TITLE=Michael Abrash's Graphics Programming Black Book Special Edition//-->
  <!--AUTHOR=Michael Abrash//-->
  <!--PUBLISHER=The Coriolis Group, Inc.//-->
  <!--CHAPTER=12//-->
  <!--PAGES=241-243//-->
  <!--UNASSIGNED1//-->
  <!--UNASSIGNED2//-->
</head>

<body>
  <center>
    <table border="1">
      <tr>
        <td><a href="12-02.html">Previous</a></td>

        <td><a href="index.html">Table of Contents</a></td>

        <td><a href="12-04.html">Next</a></td>
      </tr>
    </table>
  </center>

  <p><br /></p>

  <p>There is, of course, no guarantee that I&rsquo;m entirely correct about the optimizations discussed in this chapter. Without knowing the internals of the 486, all I can do is time code and make inferences from the results; I invite you to deduce your own rules and cross-check them against mine. Also, most likely there are other optimizations that I&rsquo;m unaware of. If you have further information on these or any other undocumented optimizations, please write and let me know. And, of course, if anyone from Intel is reading this and wants to give us the gospel truth, please do!</p>

  <h4 align="left"><a id="Heading8"></a>Stack Addressing and Address Pipelining</h4>

  <p>Rule #2A: Rule #2 sometimes, but not always, applies to the stack pointer when it is implicitly used to point to memory.</p>

  <p>Intel states that the stack pointer is an implied destination register for <b>CALL</b>, <b>ENTER</b>, <b>LEAVE</b>, <b>RET</b>, <b>PUSH</b>, and <b>POP</b> (which alter (E)SP), and that it is the implied base addressing register for <b>PUSH</b>, <b>POP</b>, and <b>RET</b> (which use (E)SP to address memory). Intel then implies that the aforementioned addressing pipeline penalty is incurred whenever the stack pointer is used as a destination by one of the first set of instructions and is then immediately used to address memory by one of the second set. This raises the specter of unpleasant programming contortions such as intermixing <b>PUSH</b>es and <b>POP</b>s with other instructions to avoid interrupting the addressing pipeline. Fortunately, matters are actually not so grim as Intel&rsquo;s documentation would indicate; my tests indicate that the addressing pipeline penalty pops up only spottily when the stack pointer is involved.</p>

  <p>For example, you&rsquo;d certainly expect a sequence such as</p><!-- CODE SNIP //-->
  <pre>
:
pop    ax
ret
pop    ax
et
:
</pre><!-- END CODE SNIP //-->

  <p>to exhibit the addressing pipeline interruption phenomenon (SP is both destination and addressing register for both instructions, according to Intel), but this code runs in six cycles per <b>POP/RET</b> pair, matching the official execution times exactly. Likewise, a sequence like</p><!-- CODE SNIP //-->
  <pre>
pop    dx
pop    cx
pop    bx
pop    ax
</pre><!-- END CODE SNIP //-->

  <p>runs in one cycle per instruction, just as it should.</p>

  <p>On the other hand, performing arithmetic directly on SP as an <i>explicit</i> destination&mdash;for example, to deallocate local variables&mdash;and then using <b>PUSH</b>, <b>POP</b>, or <b>RET</b>, definitely can interrupt the addressing pipeline. For example</p><!-- CODE SNIP //-->
  <pre>
add    sp,10h
ret
</pre><!-- END CODE SNIP //-->

  <p>loses two cycles because SP is the explicit destination of one instruction and then the implied addressing register for the next, and the sequence</p><!-- CODE SNIP //-->
  <pre>
add    sp,10h
pop    ax
</pre><!-- END CODE SNIP //-->

  <p>loses two cycles for the same reason.</p>

  <p>I certainly haven&rsquo;t tried all possible combinations, but the results so far indicate that the stack pointer incurs the addressing pipeline penalty only if (E)SP is the <i>explicit</i> destination of one instruction and is then used by one of the two following instructions to address memory. So, for instance, SP isn&rsquo;t the explicit operand of <b>POP AX&mdash;</b>AX is&mdash;and no cycles are lost if <b>POP AX</b> is followed by <b>POP</b> or <b>RET</b>. Happily, then, we need not worry about the sequence in which we use <b>PUSH</b> and <b>POP</b>. However, adding to, moving to, or subtracting from the stack pointer should ideally be done at least two cycles before <b>PUSH</b>, <b>POP</b>, <b>RET</b>, or any other instruction that uses the stack pointer to address memory.</p>

  <h4 align="left"><a id="Heading9"></a>Problems with Byte Registers</h4>

  <p>There are two ways to lose cycles by using byte registers, and neither of them is documented by Intel, so far as I know. Let&rsquo;s start with the lesser and simpler of the two.</p>

  <p>Rule #3: Do not load a byte portion of a register during one instruction, then use that register in its entirety as a source register during the next instruction.</p>

  <p>So, for example, it would be a bad idea to do this</p><!-- CODE SNIP //-->
  <pre>
mov    ah,o
            :
mov    cx,[MemVar1]
mov    al,[MemVar2]
add    cx,ax
</pre><!-- END CODE SNIP //-->

  <p>because AL is loaded by one instruction, then AX is used as the source register for the next instruction. A cycle can be saved simply by rearranging the instructions so that the byte register load isn&rsquo;t immediately followed by the word register usage, like so:</p><!-- CODE SNIP //-->
  <pre>
mov    ah,o
            :
mov    al,[MemVar2]
mov    cx,[MemVar1]
add    cx,ax
</pre><!-- END CODE SNIP //-->

  <p>Strange as it may seem, this rule is neither arbitrary nor nonsensical. Basically, when a byte destination register is part of a word source register for the next instruction, the 486 is unable to directly use the result from the first instruction as the source for the second instruction, because only part of the register required by the second instruction is contained in the first instruction&rsquo;s result. The full, updated register value must be read from the register file, and that value can&rsquo;t be read out until the result from the first instruction has been written <i>into</i> the register file, a process that takes an extra cycle. I&rsquo;m not going to explain this in great detail because it&rsquo;s not important that you understand why this rule exists (only that it <i>does</i> in fact exist), but it is an interesting window on the way the 486 works.</p>

  <p>In case you&rsquo;re curious, there&rsquo;s no such penalty for the typical <b>XLAT</b> sequence like</p><!-- CODE SNIP //-->
  <pre>
mov    bx,offset MemTable
       :
mov    al,[si]
xlat
</pre><!-- END CODE SNIP //-->

  <p>even though AL must be converted to a word by <b>XLAT</b> before it can be added to BX and used to address memory. In fact, none of the penalties mentioned in this chapter apply to <b>XLAT</b>, apparently because <b>XLAT</b> is so slow&mdash;4 cycles&mdash;that it gives the 486 time to perform addressing calculations during the course of the instruction.</p>

  <table width="100%">
    <tr>
      <td align="left" valign="top" width="5%"><img src="images/i.jpg" /></td>

      <td align="left" valign="top" width="95%"><small><i>While it&rsquo;s nice that <b>XLAT</b> doesn&rsquo;t suffer from the various 486 addressing penalties, the reason for that is basically that <b>XLAT</b> is slow, so there&rsquo;s still no compelling reason to use <b>XLAT</b> on the 486.</i></small></td>
    </tr>
  </table>

  <p>In general, penalties for interrupting the 486&rsquo;s pipeline apply primarily to the fast core instructions of the 486, most notably register-only instructions and <b>MOV</b>, although arithmetic and logical operations that access memory are also often affected. I don&rsquo;t know all the performance dependencies, and I don&rsquo;t plan to; figuring all of them out would be a big, boring job of little value. Basically, on the 486 you should concentrate on using those fast core instructions when performance matters, and all the rules I&rsquo;ll discuss do indeed apply to those instructions.</p>

  <p><br /></p>

  <center>
    <table border="1">
      <tr>
        <td><a href="12-02.html">Previous</a></td>

        <td><a href="index.html">Table of Contents</a></td>

        <td><a href="12-04.html">Next</a></td>
      </tr>
    </table>
  </center>
  <hr width="90%" size="1" noshade="noshade" />

  <div align="center">
    Graphics Programming Black Book &copy; 2001 Michael Abrash
  </div><!-- all of the reference materials (books) have the footer and subfoot reveresed -->
  <!-- reference_subfoot = footer -->
  <!-- reference_footer = subfoot -->
  <!-- BEGIN SUB FOOTER -->
  <!-- END FOOTER -->
</body>
</html>
