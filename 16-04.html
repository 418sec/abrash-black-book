<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta name="vsisbn" content="1576101746" />
  <meta name="vstitle" content="Michael Abrash's Graphics Programming Black Book, Special Edition" />
  <meta name="vsauthor" content="Michael Abrash" />
  <meta name="vspublisher" content="The Coriolis Group" />
  <meta name="vspubdate" content="07/01/97" />
  <meta name="vscategory" content="Web and Software Development: Game Development,Web and Software Development: Graphics and Multimedia Development" />

  <title>Michael Abrash's Graphics Programming Black Book Special Edition: There Ain't No Such Thing as the Fastest Code</title>
  <meta name="chapter" content="16" />
  <meta name="pages" content="305-308" />
</head>

<body>
  <center>
    <table border="1">
      <tr>
        <td>
          <a href="16-03.html">Previous</a>
        </td>

        <td>
          <a href="index.html">Table of Contents</a>
        </td>

        <td>
          <a href="16-05.html">Next</a>
        </td>
      </tr>
    </table>
  </center>

  <p>Truth to tell, I didn&rsquo;t expect a three-times speedup; around two times was what I had in mind. Which just goes to show that any code can be made faster than you&rsquo;d expect, if you think about it long enough and from many different perspectives. (The most potent word-counting technique seems to be a 64K lookup table that allows handling two bytes simultaneously. This is not the sort of technique one comes up with by brute-force optimization.) Thinking (or, worse yet, boasting) that your code is the fastest possible is rollescating on a tightrope in a hurricane; you&rsquo;re due for a fall, if you catch my drift. Case in point: Terje Mathisen&rsquo;s word-counting program.</p>

  <h4 id="Heading6">Blinding Yourself to a Better Approach</h4>

  <p>Not so long ago, Terje Mathisen, who I introduced earlier in this book, wrote a very fast word-counting program, and posted it on Bix. When I say it was fast, I mean <i>fast;</i> this code was optimized like nobody&rsquo;s business. We&rsquo;re talking top-quality code here.</p>

  <p>When the topic of optimizing came up in one of the Bix conferences, Terje&rsquo;s program was mentioned, and he posted the following message: &ldquo;I challenge BIXens (and especially <b>mabrash!</b>) to speed it up significantly. I would consider 5 percent a good result.&rdquo; The clear implication was, &ldquo;That code is as fast as it can possibly be.&rdquo;</p>

  <p>Naturally, it wasn&rsquo;t; there ain&rsquo;t no such thing as the fastest code (TANSTATFC? I agree, it doesn&rsquo;t have the ring of TANSTAAFL). I pored over Terje&rsquo;s 386 native-mode code, and found the critical inner loop, which was indeed as tight as one could imagine, consisting of just a few 386 native-mode instructions. However, one of the instructions was this:</p>
  <pre>
 
 CMP   DH,[EBX+EAX]
 
</pre>

  <p>Harmless enough, save for two things. First, EBX happened to be zero at this point (a leftover from an earlier version of the code, as it turned out), so it was superfluous as a memory-addressing component; this made it possible to use base-only addressing (<b>[EAX]</b>) rather than base+index addressing (<b>[EBX+EAX]</b>), which saves a cycle on the 386. Second: Changing the instruction to <b>CMP [EAX],DH</b> saved 2 cycles&mdash;just enough, by good fortune, to speed up the whole program by 5 percent.</p>

  <table width="100%">
    <tr>
      <td align="left" valign="top" width="5%"><img src="images/i.jpg" /></td>

      <td align="left" valign="top" width="95%"><small><i><b>CMP reg,[mem]</b> takes 6 cycles on the 386, but <b>CMP [ mem ],reg</b> takes only 5 cycles; you should always perform<b>CMP</b> with the memory operand on the left on the 386.</i></small></td>
    </tr>
  </table>

  <p>(Granted, <b>CMP [<i>mem</i>],<i>reg</i></b> is 1 cycle slower than <b>CMP <i>reg</i>,[<i>mem</i>]</b> on the 286, and they&rsquo;re both the same on the 8088; in this case, though, the code was specific to the 386. In case you&rsquo;re curious, both forms take 2 cycles on the 486; quite a lot faster, eh?)</p>

  <h4 id="Heading7">Watch Out for Luggable Assumptions!</h4>

  <p>The first lesson to be learned here is not to lug assumptions that may no longer be valid from the 8088/286 world into the wonderful new world of 386 native-mode programming. The second lesson is that after you&rsquo;ve slaved over your code for a while, you&rsquo;re in no shape to see its flaws, or to be able to get the new perspectives needed to speed it up. I&rsquo;ll bet Terje looked at that <b>[EBX+EAX]</b> addressing a hundred times while trying to speed up his code, but he didn&rsquo;t really see what it did; instead, he saw what it was supposed to do. Mental shortcuts like this are what enable us to deal with the complexities of assembly language without overloading after about 20 instructions, but they can be a major problem when looking over familiar code.</p>

  <p>The third, and most interesting, lesson is that a far more fruitful optimization came of all this, one that nicely illustrates that cycle counting is not the key to happiness, riches, and wondrous performance. After getting my 5 percent speedup, I mentioned to Terje the possibility of using a 64K lookup table. (This predated the arrival of entries for the optimization contest.) He said that he had considered it, but it didn&rsquo;t seem to him to be worthwhile. He couldn&rsquo;t shake the thought, though, and started to poke around, and one day, <i>voila,</i> he posted a new version of his word count program, WC50, that was <i>much</i> faster than the old version. I don&rsquo;t have exact numbers, but Terje&rsquo;s preliminary estimate was 80 percent faster, and word counting&mdash;<i>including</i> disk cache access time&mdash;proceeds at more than 3 MB per second on a 33 MHz 486. Even allowing for the speed of the 486, those are very impressive numbers indeed.</p>

  <p>The point I want to make, though, is that the biggest optimization barrier that Terje faced was that he <i>thought</i> he had the fastest code possible. Once he opened up the possibility that there were faster approaches, and looked beyond the specific approach that he had so carefully optimized, he was able to come up with code that was a <i>lot</i> faster. Consider the incongruity of Terje&rsquo;s willingness to consider a 5 percent speedup significant in light of his later near-doubling of performance.</p>

  <table width="100%">
    <tr>
      <td align="left" valign="top" width="5%"><img src="images/i.jpg" /></td>

      <td align="left" valign="top" width="95%"><small><i>Don&rsquo;t get stuck in the rut of instruction-by-instruction optimization. It&rsquo;s useful in key loops, but very often, a change in approach will work far greater wonders than any amount of cycle counting can.</i></small></td>
    </tr>
  </table>

  <p>By the way, Terje&rsquo;s WC50 program is a full-fledged counting program; it counts characters, words, and lines, can handle multiple files, and lets you specify the characters that separate words, should you so desire. Source code is provided as part of the archive WC50 comes in. All in all, it&rsquo;s a nice piece of work, and you might want to take a look at it if you&rsquo;re interested in really fast assembly code. I wouldn&rsquo;t call it the <i>fastest</i> word-counting code, though, because I would of course never be so foolish as to call <i>anything</i> the fastest.</p>

  <h3 id="Heading8">The Astonishment of Right-Brain Optimization</h3>

  <p>As it happened, the challenge I issued to my <i>PC TECHNIQUES</i> readers was a smashing success, with dozens of good entries. I certainly enjoyed it, even though I did have to look at a <i>lot</i> of tricky assembly code that I didn&rsquo;t write&mdash;hard work under the best of circumstances. It was worth the trouble, though. The winning entry was an astonishing example of what assembly language can do in the right hands; on my 386, it was <i>four times</i> faster at word counting than the nice, tight assembly code I provided as a starting point&mdash;and about 13 times faster than the original C implementation. Attention, high-level language chauvinists: Is the speedup getting significant yet? Okay, maybe word counting isn&rsquo;t the most critical application, but how would you like to have that kind of improvement in your compression software, or in your real-time games&mdash;or in Windows graphics?</p>

  <p>The winner was David Stafford, who at the time was working for Borland International; his entry is shown in Listing 16.5. Dave Methvin, whom some of you may recall as a tech editor of the late, lamented <i>PC Tech Journal,</i> was a close second, and Mick Brown, about whom I know nothing more than that he is obviously an extremely good assembly language programmer, was a close third, as shown in Table 16.2, which precedes Listing 16.5. Those three were out ahead of the pack; the fourth-place entry, good as it was (twice as fast as my original code), was twice as slow as David&rsquo;s winning entry, so you can see that David, Dave, and Mick attained a rarefied level of optimization indeed.</p>

  <center>
    <table border="1">
      <tr>
        <td>
          <a href="16-03.html">Previous</a>
        </td>

        <td>
          <a href="index.html">Table of Contents</a>
        </td>

        <td>
          <a href="16-05.html">Next</a>
        </td>
      </tr>
    </table>
  </center>
  <hr width="90%" size="1" noshade="noshade" />

  <div align="center">
    Graphics Programming Black Book &copy; 2001 Michael Abrash
  </div>
</body>
</html>
